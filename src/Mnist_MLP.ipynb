{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import logging\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns of training dataset to be used. We will seggregate csv file into label and training data.\n",
    "usecols = [i for i in range(1, 785)];\n",
    "\n",
    "label_csv = numpy.loadtxt('../data/train_orig.csv', delimiter = ',', usecols = 0, skiprows = 1, dtype = int)\n",
    "train_csv = numpy.loadtxt('../data/train_orig.csv', delimiter = ',', usecols = usecols, skiprows = 1, dtype = float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Columns of test dataset to be used. For test data all the columns will be utilized.\n",
    "testcols = [i for i in range(0, 785)]\n",
    "\n",
    "test_iter = mx.io.CSVIter(data_csv = '../data/test.csv', data_shape = (784, ), batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy Array to NDArrayIter that MXNet sym utilizes\n",
    "train_iter = mx.io.NDArrayIter(data = train_csv, label = label_csv, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets look at the distribution of training data\n",
    "#xbins = [x for x in range(0, 11)]\n",
    "#plt.hist(mnist['train_label'], xbins)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The first fully-connected layer and the corresponding activation function\n",
    "fc1  = mx.sym.FullyConnected(data=data, num_hidden=128)\n",
    "act1 = mx.sym.Activation(data=fc1, act_type=\"relu\")\n",
    "\n",
    "# The second fully-connected layer and the corresponding activation function\n",
    "fc2  = mx.sym.FullyConnected(data=act1, num_hidden = 64)\n",
    "act2 = mx.sym.Activation(data=fc2, act_type=\"relu\")\n",
    "\n",
    "fc3  = mx.sym.FullyConnected(data=act2, num_hidden = 256)\n",
    "act3 = mx.sym.Activation(data=fc3, act_type=\"tanh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST has 10 classes\n",
    "fc4  = mx.sym.FullyConnected(data=act3, num_hidden=10)\n",
    "# Softmax with cross entropy loss\n",
    "mlp  = mx.sym.SoftmaxOutput(data=fc4, name='softmax')\n",
    "shape = {\"data\" : (batch_size, 1, 28, 28)}\n",
    "mx.viz.plot_network(symbol=mlp, shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)  # logging to stdout\n",
    "# create a trainable module on CPU\n",
    "mlp_model = mx.mod.Module(symbol=mlp, context=mx.cpu())\n",
    "\n",
    "mlp_model.fit(train_iter,  # train data\n",
    "              eval_data=None,  # validation data\n",
    "              optimizer='sgd',  # use SGD to train\n",
    "              optimizer_params={'learning_rate':0.1},  # use fixed learning rate\n",
    "              eval_metric='acc',  # report accuracy during training\n",
    "              batch_end_callback = mx.callback.Speedometer(batch_size, 50), # output progress for each 100 data batches\n",
    "              num_epoch=1)  # train for at most 10 dataset passes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = mlp_model.predict(test_iter)\n",
    "lenOutput = prob.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputFileName = '../output/output.' + str(datetime.now()) + \".csv\";\n",
    "with open(outputFileName, 'w') as outputFile:\n",
    "    outputWriter = csv.writer(outputFile, delimiter=',');\n",
    "    outputWriter.writerow(['ImageId','Label']);\n",
    "    imageId = 1;\n",
    "    for i in range(0, lenOutput-1):\n",
    "        output = prob[i]\n",
    "        outputWriter.writerow([str(imageId)] + [str(numpy.argmax(output.asnumpy()))]);\n",
    "        imageId += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
